{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**INRODUCTION:**\n\nThis project aims to predict if a particular request for loan approval be approved or not. It uses various variables to determine it like education,income ,dependents of the person applying for loan and many other parameters. ","metadata":{}},{"cell_type":"markdown","source":"**ACNOWLEDGEMENT**\n\nThe datset I have chosen is from kaggle itself. To see the datset [click here](https://www.kaggle.com/datasets/rishikeshkonapure/home-loan-approval)","metadata":{}},{"cell_type":"markdown","source":"****Process for model building:****\n1. Importing dataset and all the important libraries\n2. Understanding the data\n3. Cleaning and pre-processing the data\n4. Splitting the data into train and test data\n5. Compiling and training the model \n6. Evaluating its performance","metadata":{}},{"cell_type":"markdown","source":"# 1. Importing dataset and all the important libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:09.743821Z","iopub.execute_input":"2023-09-19T19:17:09.744411Z","iopub.status.idle":"2023-09-19T19:17:09.751498Z","shell.execute_reply.started":"2023-09-19T19:17:09.744368Z","shell.execute_reply":"2023-09-19T19:17:09.749837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"org_data = pd.read_csv('/kaggle/input/home-loan-approval/loan_sanction_train.csv')\nprint(org_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:09.761659Z","iopub.execute_input":"2023-09-19T19:17:09.762083Z","iopub.status.idle":"2023-09-19T19:17:09.792475Z","shell.execute_reply.started":"2023-09-19T19:17:09.762050Z","shell.execute_reply":"2023-09-19T19:17:09.790885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Understanding the data","metadata":{}},{"cell_type":"code","source":"org_data.info()\norg_data.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:09.794885Z","iopub.execute_input":"2023-09-19T19:17:09.795239Z","iopub.status.idle":"2023-09-19T19:17:09.836570Z","shell.execute_reply.started":"2023-09-19T19:17:09.795207Z","shell.execute_reply":"2023-09-19T19:17:09.835465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"org_data.hist(bins = 20, figsize = (10,8))\nprint(org_data['Gender'].value_counts())\nprint(org_data['Married'].value_counts())\nprint(org_data['Dependents'].value_counts())\nprint(org_data['Self_Employed'].value_counts())\nprint(org_data['Property_Area'].value_counts())\nprint(org_data['Loan_Status'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:09.838765Z","iopub.execute_input":"2023-09-19T19:17:09.839189Z","iopub.status.idle":"2023-09-19T19:17:11.350345Z","shell.execute_reply.started":"2023-09-19T19:17:09.839148Z","shell.execute_reply":"2023-09-19T19:17:11.346755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=6\nwhile i<11:\n    plt.scatter( org_data.iloc[: , i], org_data['Loan_Status'],)\n    plt.xlabel(str(i)+\"th Column\")\n    plt.ylabel('Loan_Status')\n    plt.show()\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:11.352117Z","iopub.execute_input":"2023-09-19T19:17:11.352566Z","iopub.status.idle":"2023-09-19T19:17:12.294103Z","shell.execute_reply.started":"2023-09-19T19:17:11.352530Z","shell.execute_reply":"2023-09-19T19:17:12.292691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Findings:**\n* There are 614 rows and 13 columns including the LoanID\n* There are a few outliers and missing values\n* More than 75% of the applicants are male and more than 70% are married\n* More than half of the applicants do not have any dependents\n* Interestingly more than 83% of applicants are self employed which possibly indicates that bank recieve a lot of requests for buisness loans\n* There is not much trend observed in area apparently which possibly means the location of bank is very strategic so people from both urban and rural areas have access to it. From user point of view, This is a positive point.\n* Finally about 68% of the requests are approved by the bank which is decent.","metadata":{}},{"cell_type":"markdown","source":"# 3. Cleaning and pre-processing the data","metadata":{}},{"cell_type":"markdown","source":"First let us fill in the missing values, Theoretically if there are missing values that row can be dropped but since we have a limited number of rows I do not want to do that so I will be filling the categorical values with mode and numerical values with the mean.","metadata":{}},{"cell_type":"code","source":"print(\"Missing Values in Original Data\")\nprint(\"\")\nmiss_vals = org_data.isnull()\nprint(miss_vals.sum())\n\nfilled_data = org_data\nmode_gender = filled_data['Gender'].mode()[0]\nfilled_data['Gender'].fillna(mode_gender, inplace = True)\n\n#filling the missing values in married column\nmode_married = filled_data['Married'].mode()[0]\nfilled_data['Married'].fillna(mode_married, inplace = True)\n\n#filling the missing values in dependents column\nmode_Dependents = filled_data['Dependents'].mode()[0]\nfilled_data['Dependents'].fillna(mode_Dependents, inplace = True)\n\n#Education column has no missing values\n\n#filling the missing values in Self_Employed column\nmode_self = filled_data['Self_Employed'].mode()[0]\nfilled_data['Self_Employed'].fillna(mode_self, inplace = True)\n\n#filling the missing values in Property_Area column\nmode_self = filled_data['Property_Area'].mode()[0]\nfilled_data['Property_Area'].fillna(mode_self, inplace = True)\n\n#filling the missing values in Credit_History column\nmode_credit = filled_data['Credit_History'].mode()[0]\nfilled_data['Credit_History'].fillna(mode_credit, inplace = True)\n\n#filling missing values in numerical columns left\nfilled_data['LoanAmount'].fillna(filled_data['LoanAmount'].mean(), inplace = True)\nfilled_data['Loan_Amount_Term'].fillna(filled_data['Loan_Amount_Term'].mean(), inplace = True)\nprint(\"\")\nprint(\"\")\nprint(\"\")\nprint(\"Missing Values in Filled Data\")\nprint(\"\")\nmiss_vals = filled_data.isnull()\nprint(miss_vals.sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.297975Z","iopub.execute_input":"2023-09-19T19:17:12.298598Z","iopub.status.idle":"2023-09-19T19:17:12.336419Z","shell.execute_reply.started":"2023-09-19T19:17:12.298544Z","shell.execute_reply":"2023-09-19T19:17:12.335014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have no missing values, so we proceed to normalize the numerical columns.  ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nnumerical_scaler = MinMaxScaler()\nencoded_data = filled_data\nencoded_data.iloc[:, 6:10]   = numerical_scaler.fit_transform(filled_data.iloc[:, 6:10])\nencoded_data = filled_data\ni=1\nwhile i<13 :\n    if i==6 :\n        i+=5\n        continue\n    encoded_data.iloc[: , i] = LabelEncoder().fit_transform(filled_data.iloc[: , i])\n    i+=1\nprint(encoded_data.head())\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.338116Z","iopub.execute_input":"2023-09-19T19:17:12.338540Z","iopub.status.idle":"2023-09-19T19:17:12.373515Z","shell.execute_reply.started":"2023-09-19T19:17:12.338504Z","shell.execute_reply":"2023-09-19T19:17:12.372167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Splitting the data into train and test data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train , X_test , Y_train , Y_test = train_test_split(encoded_data.iloc[: ,1:12] , encoded_data.iloc[:,12] , test_size = 0.2 , random_state =2)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.375344Z","iopub.execute_input":"2023-09-19T19:17:12.375850Z","iopub.status.idle":"2023-09-19T19:17:12.396307Z","shell.execute_reply.started":"2023-09-19T19:17:12.375810Z","shell.execute_reply":"2023-09-19T19:17:12.394734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, Y_train.shape)\nlabel_encoder = LabelEncoder()\nY_train_encoded = label_encoder.fit_transform(Y_train)\nY_test_encoded = label_encoder.fit_transform(Y_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.398066Z","iopub.execute_input":"2023-09-19T19:17:12.398488Z","iopub.status.idle":"2023-09-19T19:17:12.414144Z","shell.execute_reply.started":"2023-09-19T19:17:12.398455Z","shell.execute_reply":"2023-09-19T19:17:12.412518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Compiling and training the model","metadata":{}},{"cell_type":"code","source":"log_model = LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.416048Z","iopub.execute_input":"2023-09-19T19:17:12.416442Z","iopub.status.idle":"2023-09-19T19:17:12.426618Z","shell.execute_reply.started":"2023-09-19T19:17:12.416409Z","shell.execute_reply":"2023-09-19T19:17:12.425284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_model.fit(X_train,Y_train_encoded)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.428795Z","iopub.execute_input":"2023-09-19T19:17:12.429663Z","iopub.status.idle":"2023-09-19T19:17:12.456759Z","shell.execute_reply.started":"2023-09-19T19:17:12.429614Z","shell.execute_reply":"2023-09-19T19:17:12.455509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Evaluating its performance","metadata":{}},{"cell_type":"code","source":"#Accuracy on training data\nX_train_predicted = log_model.predict(X_train)\ntraining_data_accuracy = accuracy_score(X_train_predicted,Y_train_encoded)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.461486Z","iopub.execute_input":"2023-09-19T19:17:12.461895Z","iopub.status.idle":"2023-09-19T19:17:12.472192Z","shell.execute_reply.started":"2023-09-19T19:17:12.461861Z","shell.execute_reply":"2023-09-19T19:17:12.470770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy on test data\n\nX_test_predicted = log_model.predict(X_test)\ntest_data_accuracy = accuracy_score(X_test_predicted,Y_test_encoded)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.473902Z","iopub.execute_input":"2023-09-19T19:17:12.474297Z","iopub.status.idle":"2023-09-19T19:17:12.489358Z","shell.execute_reply.started":"2023-09-19T19:17:12.474264Z","shell.execute_reply":"2023-09-19T19:17:12.488267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy on Training Data: ',round((training_data_accuracy*100) ,2) , \"%\")\nprint('Accuracy on Test Data: ',round((test_data_accuracy*100) ,2) , \"%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.491389Z","iopub.execute_input":"2023-09-19T19:17:12.492241Z","iopub.status.idle":"2023-09-19T19:17:12.506349Z","shell.execute_reply.started":"2023-09-19T19:17:12.492203Z","shell.execute_reply":"2023-09-19T19:17:12.505163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion \nSo this model is able to predict whether a request will be accepted or not based on following parameters with an accuracy of about 77%. Please note that the data points were only about 120 for testing while traing accuracy was achieved as high as about 82%.","metadata":{}},{"cell_type":"markdown","source":"Finally I am using the same model to predict the values given in test data in the same datset I used for training. Final predictions are present below.","metadata":{}},{"cell_type":"code","source":"org_test_data = pd.read_csv('/kaggle/input/home-loan-approval/loan_sanction_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.508694Z","iopub.execute_input":"2023-09-19T19:17:12.509353Z","iopub.status.idle":"2023-09-19T19:17:12.528745Z","shell.execute_reply.started":"2023-09-19T19:17:12.509303Z","shell.execute_reply":"2023-09-19T19:17:12.526427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Missing Values in Original Test Data\")\nprint(\"\")\nmiss_test_vals = org_test_data.isnull()\nprint(miss_test_vals.sum())\n\nfilled_test_data = org_test_data\nmode_gender = filled_test_data['Gender'].mode()[0]\nfilled_test_data['Gender'].fillna(mode_gender, inplace = True)\n\n#filling the missing values in married column\nmode_married = filled_test_data['Married'].mode()[0]\nfilled_test_data['Married'].fillna(mode_married, inplace = True)\n\n#filling the missing values in dependents column\nmode_Dependents = filled_test_data['Dependents'].mode()[0]\nfilled_test_data['Dependents'].fillna(mode_Dependents, inplace = True)\n\n#Education column has no missing values\n\n#filling the missing values in Self_Employed column\nmode_self = filled_test_data['Self_Employed'].mode()[0]\nfilled_test_data['Self_Employed'].fillna(mode_self, inplace = True)\n\n#filling the missing values in Property_Area column\nmode_self = filled_test_data['Property_Area'].mode()[0]\nfilled_test_data['Property_Area'].fillna(mode_self, inplace = True)\n\n#filling the missing values in Credit_History column\nmode_credit = filled_test_data['Credit_History'].mode()[0]\nfilled_test_data['Credit_History'].fillna(mode_credit, inplace = True)\n\n#filling missing values in numerical columns left\nfilled_test_data['LoanAmount'].fillna(filled_test_data['LoanAmount'].mean(), inplace = True)\nfilled_test_data['Loan_Amount_Term'].fillna(filled_test_data['Loan_Amount_Term'].mean(), inplace = True)\nprint(\"\")\nprint(\"\")\nprint(\"\")\nprint(\"Missing Values in Filled Data\")\nprint(\"\")\nmiss_test_vals = filled_test_data.isnull()\nprint(miss_vals.sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.531218Z","iopub.execute_input":"2023-09-19T19:17:12.531699Z","iopub.status.idle":"2023-09-19T19:17:12.561295Z","shell.execute_reply.started":"2023-09-19T19:17:12.531651Z","shell.execute_reply":"2023-09-19T19:17:12.559967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nnumerical_scaler = MinMaxScaler()\nencoded_test_data = filled_test_data.copy()\n\n# Scale numerical columns (assuming columns 6 to 9 are numerical)\nencoded_test_data.iloc[:, 6:10] = numerical_scaler.fit_transform(filled_test_data.iloc[:, 6:10])\n\ni = 1\nwhile i < 12:\n    if i == 6:\n        i += 5\n        continue\n    if i >= len(encoded_test_data.columns):\n        print(\"haha\" , len(encoded_test_data.columns))\n        break  # Exit the loop if i is out of bounds\n    encoded_test_data.iloc[:, i] = LabelEncoder().fit_transform(filled_test_data.iloc[:, i])\n    i += 1\n\nprint(encoded_test_data.head())\n\ntest_data_final = encoded_test_data.iloc[:, 1:12]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.563505Z","iopub.execute_input":"2023-09-19T19:17:12.564442Z","iopub.status.idle":"2023-09-19T19:17:12.590558Z","shell.execute_reply.started":"2023-09-19T19:17:12.564395Z","shell.execute_reply":"2023-09-19T19:17:12.589168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = log_model.predict(test_data_final)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.592232Z","iopub.execute_input":"2023-09-19T19:17:12.592718Z","iopub.status.idle":"2023-09-19T19:17:12.614169Z","shell.execute_reply.started":"2023-09-19T19:17:12.592652Z","shell.execute_reply":"2023-09-19T19:17:12.612603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T19:17:12.615998Z","iopub.execute_input":"2023-09-19T19:17:12.616368Z","iopub.status.idle":"2023-09-19T19:17:12.631111Z","shell.execute_reply.started":"2023-09-19T19:17:12.616335Z","shell.execute_reply":"2023-09-19T19:17:12.630123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}